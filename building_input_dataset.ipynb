{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training data set\n",
    "\n",
    "Toolkit to transform the [Husser 2013](http://adsabs.harvard.edu/abs/2013A%26A...553A...6H) grid of stellar atmosphere models to the form useful as training data for the neural network limb darkening approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The grid of atmosphere models was accessed from [http://phoenix.astro.physik.uni-goettingen.de/](http://phoenix.astro.physik.uni-goettingen.de/) on 28th March 2017. The required data are stored in the `spec_int` files, which for each model atmosphere contain a spectral intensity value for a range of (~80) angles of $\\mu$ for every 0.1 nm in the range 50 - 2600 nm.\n",
    "\n",
    "The form of training data required for the neural network is for a particular bandpass, for example *Kepler*, the training input values are the stellar atmospheric parameters ($T_eff$, $\\log g$ and $[Fe/H]$) as well as cosine of the limb angle ($\\mu$), with the output as the value of the intensity.\n",
    "\n",
    "To produce the intensity values for each model atmosphere and limb angle, the spectral intensity information from the model atmosphere must be convolved with the spectral response curve of the filter and that is then integrated over wavelength.\n",
    "\n",
    "The key steps required are:\n",
    "- Build a function for one stellar atmosphere model\n",
    "    - to convolve with each bandpass\n",
    "    - integrate over wavelength\n",
    "    - for each given mu angle\n",
    "    - correct for radius definition\n",
    "- Loop through all of the atmosphere models\n",
    "- Export to file\n",
    "\n",
    "This notebook goes through these steps to produce the entire grid of training data for a range of wavelengths and few other corrections required along the way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Firstly import the packages required..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pylab inline\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import simps\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.utils.console import ProgressBar\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model atmospheres\n",
    "\n",
    "Below the function to read in the required information from the model atmosphere files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_PHOENIX(chosen_path):\n",
    "    with fits.open(chosen_path) as f:\n",
    "        I = (f[0].data)/100.           # matrix of spectral intensity values, scaled down for easier calculations\n",
    "        mu = f['MU'].data              # mu values spectral intensity is calculated for in this model\n",
    "        CRVAL1 = f[0].header['CRVAL1'] # wavelength start value (in Angstrom)\n",
    "        CDELT1 = f[0].header['CDELT1'] # wavelength step size (in Angstrom)\n",
    "        teff = f[0].header['PHXTEFF']  # effective temperature of model (K)\n",
    "        logg = f[0].header['PHXLOGG']  # log g of model\n",
    "        feh = f[0].header['PHXM_H']    # metallicity of model\n",
    "    wavelengths = (np.arange(I.shape[1]) * CDELT1 + CRVAL1)/10. # convert to nm to match response functions\n",
    "    return wavelengths, I, mu, teff, logg, feh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now locate all the atmosphere models, with the list of paths stored in: `model_list`\n",
    "\n",
    "**Note:** this will only work if the models are stored in the same location on the computer this is run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "model_list.extend(glob.glob('../phoenix2011/Z-0.0/*.fits'))\n",
    "model_list.extend(glob.glob('../phoenix2011/Z-0.5/*.fits'))\n",
    "model_list.extend(glob.glob('../phoenix2011/Z-1.0/*.fits'))\n",
    "model_list.extend(glob.glob('../phoenix2011/Z-1.5/*.fits'))\n",
    "model_list.extend(glob.glob('../phoenix2011/Z-2.0/*.fits'))\n",
    "model_list.extend(glob.glob('../phoenix2011/Z-3.0/*.fits'))\n",
    "model_list.extend(glob.glob('../phoenix2011/Z-4.0/*.fits'))\n",
    "model_list.extend(glob.glob('../phoenix2011/Z+0.5/*.fits'))\n",
    "model_list.extend(glob.glob('../phoenix2011/Z+1.0/*.fits'))\n",
    "print(\"Number of models found: \",len(model_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bandpasses\n",
    "\n",
    "The locations of each of the response functions are defined in the following dictionary, and are then loaded into memory in the dictionary, `filters`\n",
    "\n",
    "More information about each of the bandpasses included can be found in the [README](./response_functions/0_README.md) file in the directory with the response functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transmission = {'Kp' : './response_functions/kepler_response.txt',\n",
    "                'S1' : './response_functions/spitzer_1.txt',\n",
    "                'S2' : './response_functions/spitzer_2.txt',\n",
    "                'S3' : './response_functions/spitzer_3.txt',\n",
    "                'S4' : './response_functions/spitzer_4.txt',\n",
    "                'u'  : './response_functions/Stroemgren_u.txt',\n",
    "                'v'  : './response_functions/Stroemgren_v.txt',\n",
    "                'b'  : './response_functions/Stroemgren_b.txt',\n",
    "                'y'  : './response_functions/Stroemgren_y.txt',\n",
    "                'U'  : './response_functions/Bessel_U-1.txt',\n",
    "                'V'  : './response_functions/Bessel_V-1.txt',\n",
    "                'B'  : './response_functions/Bessel_B-1.txt',\n",
    "                'R'  : './response_functions/Bessel_R-1.txt',\n",
    "                'I'  : './response_functions/Bessel_I-1.txt',\n",
    "                'J'  : './response_functions/2MASS_Jband.txt',\n",
    "                'H'  : './response_functions/2MASS_Hband.txt',\n",
    "                'K'  : './response_functions/2MASS_Kband.txt',\n",
    "                'u_' : './response_functions/SDSS_u.txt',\n",
    "                'g_' : './response_functions/SDSS_g.txt',\n",
    "                'r_' : './response_functions/SDSS_r.txt',\n",
    "                'i_' : './response_functions/SDSS_i.txt',\n",
    "                'z_' : './response_functions/SDSS_z.txt',\n",
    "                'vT' : './response_functions/v_tycho.txt',\n",
    "                'bT' : './response_functions/b_tycho.txt',\n",
    "                'Cp' : './response_functions/cheops.txt'\n",
    "               }\n",
    "filters = {}\n",
    "for filt in transmission:\n",
    "    filters[filt] = np.loadtxt(transmission[filt])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the calculated wavelengths in each model atmosphere output file are the same, we can save some time by interpolating the bandpasses for each filter to match the PHOENIX model output for the convolution and integration step. The interpolated bandpasses are then stored in the dictionary, `filt_int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_wavelengths, _I, _mu, _teff, _logg, _feh = read_PHOENIX(model_list[409])\n",
    "\n",
    "filt_int = {}\n",
    "for filt in filters:\n",
    "    filt_int[filt] = np.interp(init_wavelengths,filters[filt][:,0],filters[filt][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example spectrum\n",
    "\n",
    "To demonstrate the process involved in producing the grid, here are a couple of example plots.\n",
    "\n",
    "Below is a plot of the model atmosphere output at 2 different limb angles (shown in red), plotted with the *Kepler* spectral response (shown in orange), and the result of the convolution of the two for each limb angle (shown in blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_filt_spec = (_I * filt_int['Kp']).T\n",
    "print('Example model:',model_list[409])\n",
    "print('Effective temperature:',_teff,'K, log g:',_logg,', [Fe/H]:',_feh)\n",
    "\n",
    "j = 40\n",
    "cp = sb.color_palette('deep')\n",
    "with sb.axes_style('white'):\n",
    "    fig,axs = plt.subplots(1,2,figsize=(12,5))\n",
    "    axs2 = axs[0].twinx()\n",
    "    \n",
    "    axs[0].plot(init_wavelengths,_filt_spec[:,-1]/np.max(_filt_spec[:,-1]),lw=0.5,alpha=0.7,label=r'$F_{\\lambda} S_{\\lambda}$')\n",
    "    axs2.plot(init_wavelengths,_I[-1,:],lw=0.5,c=cp[2],alpha=0.7,label=r'$F_{\\lambda}$')\n",
    "    axs[0].plot(init_wavelengths,filt_int['Kp']/np.max(filt_int['Kp']),label=r'$S_{\\lambda}$')\n",
    "    axs[0].legend(loc=2)\n",
    "    axs2.legend(loc=1)\n",
    "    \n",
    "    axs4 = axs[1].twinx()\n",
    "    \n",
    "    axs[1].plot(init_wavelengths,_filt_spec[:,j]/np.max(_filt_spec[:,j]),lw=0.5,alpha=0.7,label=r'$F_{\\lambda} S_{\\lambda}$')\n",
    "    axs4.plot(init_wavelengths,_I[j,:],lw=0.5,c=cp[2],alpha=0.7,label=r'$F_{\\lambda}$')\n",
    "    axs[1].plot(init_wavelengths,filt_int['Kp']/np.max(filt_int['Kp']),label=r'$S_{\\lambda}$')\n",
    "    axs[1].legend(loc=2)\n",
    "    axs4.legend(loc=1)\n",
    "    \n",
    "    plt.setp(axs[0],title=r'$\\mu$ = 1')\n",
    "    plt.setp(axs[1],title=r'$\\mu$ = '+str(_mu[j]))\n",
    "    plt.setp(axs[0],xlim=[330,1000])\n",
    "    plt.setp(axs[1],xlim=[330,1000])\n",
    "    plt.setp(axs[0],xlabel=r'wavelength, nm',ylabel=r'scaled intensity / scaled transmission')\n",
    "    plt.setp(axs2,ylabel=r'spectral flux')\n",
    "    plt.setp(axs2,ylim=[0,6e12])\n",
    "    plt.setp(axs[1],xlabel=r'wavelength, nm')\n",
    "    plt.setp(axs4,ylabel=r'spectral flux')\n",
    "    plt.setp(axs4,ylim=[0,1e12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that same model atmosphere, here is the limb profile for the *Kepler* bandpass as a result of intergrating the above convolutions with respect to wavelength for each limb angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_flux = []\n",
    "for j in range(_mu.shape[0]):\n",
    "    _flux.append(simps(_filt_spec[:,j],init_wavelengths))\n",
    "\n",
    "_flux = _flux/(_flux[-1])\n",
    "_flux = np.array(_flux)\n",
    "    \n",
    "with sb.axes_style('darkgrid'):\n",
    "    fig,axs = plt.subplots(1,1,figsize=(5,4))\n",
    "    axs.plot(_mu,_flux,marker='.')\n",
    "    plt.setp(axs,xlabel=r'$\\mu$')\n",
    "    plt.setp(axs,ylabel=r'$I_{\\lambda}(\\mu)$')\n",
    "    plt.setp(axs,xlim=[0,1],ylim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stellar radius definition\n",
    "\n",
    "As can be seen from the plot above, the stellar radius used to define the values of $\\mu$ is not the same as how we would define the edge of a star for an exoplanet transit. In order to correct for this inconsistency, we need to redefine the stellar radius as some value inside where it is currently defined and then recalculate the values for $\\mu$.\n",
    "\n",
    "Following [Espinoza et al 2015](http://adsabs.harvard.edu/abs/2015MNRAS.450.1879E) we redefine the stellar radius as the radius where the maximum gradient in intensity is found, which is defined in the function `new_get_rmax`.\n",
    "\n",
    "An example of this correction for the same model atmosphere as before is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_get_rmax(mu,I0):\n",
    "    # convert mu to r\n",
    "    r = np.sqrt(1.-(mu**2.))\n",
    "    \n",
    "    # find the maximum derivative point\n",
    "    i = np.argmax(abs(np.diff(I0)/np.diff(r)))\n",
    "    \n",
    "    # make radius correction to values inside new radius\n",
    "    r_new  = r[i:]/r[i]\n",
    "    mu_new = np.sqrt(1-r_new**2)\n",
    "    \n",
    "    ip_new = I0[i:]\n",
    "    return r_new, mu_new, ip_new, r[i], mu[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_r = np.sqrt(1.-(_mu**2.))\n",
    "\n",
    "# Also calculate limb profile for the 2MASS K band\n",
    "_filt_spec2 = (_I * filt_int['K']).T\n",
    "_flux2 = []\n",
    "for j in range(_mu.shape[0]):\n",
    "    _flux2.append(simps(_filt_spec2[:,j],init_wavelengths))\n",
    "\n",
    "_flux2 = _flux2/(_flux2[-1])\n",
    "_flux2 = np.array(_flux2)\n",
    "\n",
    "# Apply corrections\n",
    "new_r, new_mu, new_I0, _, _ = new_get_rmax(_mu,_flux) # Kepler band\n",
    "new_r2, new_mu2, new_I02, _, _ = new_get_rmax(_mu,_flux2) # Kepler band\n",
    "\n",
    "# Plotting correction\n",
    "gp = sb.color_palette(\"BuGn_r\")\n",
    "bp = sb.color_palette(\"GnBu_d\")\n",
    "with sb.axes_style('darkgrid'):\n",
    "    fig,axs = plt.subplots(2,3,figsize=(15,6),sharey='row',sharex='col')\n",
    "    \n",
    "    axs[0,0].plot(_mu,_flux,label=r'Kepler band',c=gp[1])\n",
    "    axs[0,0].plot(_mu,_flux2,label=r'2MASS K band',c=bp[1])\n",
    "    plt.setp(axs[0,0],xlim=[0,1])\n",
    "    plt.setp(axs[0,0],ylim=[0,1])\n",
    "    plt.setp(axs[0,0],ylabel=r'Scaled intensity')\n",
    "    \n",
    "    axs[0,1].plot(_r,_flux,label=r'Kepler band',c=gp[1])\n",
    "    axs[0,1].plot(_r,_flux2,label=r'2MASS K band',c=bp[1])\n",
    "    plt.setp(axs[0,1],xlim=[0,1])\n",
    "    plt.setp(axs[0,1],ylim=[0,1])\n",
    "    axs[0,1].legend()\n",
    "\n",
    "    axs[1,0].plot(new_mu,new_I0,label=r'adjusted Kepler band',c=gp[2])\n",
    "    axs[1,0].plot(new_mu2,new_I02,label=r'adjusted 2MASS K band',c=bp[2])\n",
    "    plt.setp(axs[1,0],xlim=[0,1])\n",
    "    plt.setp(axs[1,0],ylim=[0,1])\n",
    "    plt.setp(axs[1,0],xlabel=r'$\\mu$')\n",
    "    plt.setp(axs[1,0],ylabel=r'Scaled intensity')\n",
    "    \n",
    "    axs[1,1].plot(new_r,new_I0,label=r'adjusted Kepler band',c=gp[2])\n",
    "    axs[1,1].plot(new_r2,new_I02,label=r'adjusted 2MASS K band',c=bp[2])\n",
    "    plt.setp(axs[1,1],xlim=[0,1])\n",
    "    plt.setp(axs[1,1],ylim=[0,1])\n",
    "    plt.setp(axs[1,1],xlabel=r'$R / R_\\star$')\n",
    "    axs[1,1].legend()\n",
    "\n",
    "    axs[0,2].plot(_r,_flux,label=r'Kepler band',c=gp[1])\n",
    "    axs[0,2].plot(_r,_flux2,label=r'2MASS K band',c=bp[1])\n",
    "    plt.setp(axs[0,2],xlim=[0.995,1])\n",
    "    plt.setp(axs[0,2],ylim=[0,1])\n",
    "    \n",
    "    axs[1,2].plot(new_r,new_I0,label=r'adjusted Kepler band',c=gp[2])\n",
    "    axs[1,2].plot(new_r2,new_I02,label=r'adjusted 2MASS K band',c=bp[2])\n",
    "    plt.setp(axs[1,2],xlim=[0.995,1])\n",
    "    plt.setp(axs[1,2],ylim=[0,1])\n",
    "    plt.setp(axs[1,2],xlabel=r'$R / R_\\star$')\n",
    "    \n",
    "    plt.subplots_adjust(hspace = 0.1, wspace = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the grid\n",
    "\n",
    "Now we can produce the grid itself, and save the table to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Teff','logg','Z','Filt','mu','intensity','mu_fac','r_fac']\n",
    "\n",
    "grid1 = []\n",
    "grid2 = []\n",
    "\n",
    "with ProgressBar(len(model_list), ipython_widget=True) as bar:\n",
    "    for item in model_list:\n",
    "        wavelengths, I, mu, teff, logg, feh = read_PHOENIX(item)\n",
    "\n",
    "        for filt in filters:\n",
    "            filt_spec = (I * filt_int[filt]).T\n",
    "\n",
    "            flux = []\n",
    "            for j in range(mu.shape[0]):\n",
    "                flux.append(simps(filt_spec[:,j],wavelengths))\n",
    "\n",
    "            flux = flux/(flux[-1])\n",
    "            flux = np.array(flux)\n",
    "            \n",
    "            new_r,new_mu,new_I0,r_fac,mu_fac = new_get_rmax(mu,flux)\n",
    "            \n",
    "            even_mus = np.linspace(new_mu.min(),1,200)\n",
    "            interp_I = interp1d(new_mu,new_I0,kind='quadratic',assume_sorted=True)(even_mus)\n",
    "            \n",
    "            for q in range(mu.shape[0]):\n",
    "                grid1.append([teff,logg,feh,filt,mu[q],flux[q],mu_fac,r_fac])\n",
    "\n",
    "            for s in range(even_mus.shape[0]):\n",
    "                grid2.append([teff,logg,feh,filt,even_mus[s],interp_I[s],mu_fac,r_fac])\n",
    "\n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=grid1,columns=columns)\n",
    "df2 = pd.DataFrame(data=grid2,columns=columns)\n",
    "\n",
    "# for same distribution of mu as defined in model\n",
    "df.to_csv('phoenix_intensity_table.csv')\n",
    "# for 200 evenly-spaced mu values (intensities interpolated)\n",
    "df2.to_csv('phoenix_intensity_table_resampled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
